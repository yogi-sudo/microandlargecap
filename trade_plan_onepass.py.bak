#!/usr/bin/env python3
import os, sys, time, math, datetime as dt
from typing import List, Tuple, Optional
import pandas as pd, numpy as np, requests
from tqdm import tqdm

# ---- Config (env-tunable) ----
TODAY = dt.date.today()
YEARS        = int(os.getenv("YEARS", 3))
TEST_DAYS    = int(os.getenv("TEST_DAYS", 60))
TOPN_LARGE   = int(os.getenv("TOPN_LARGE", 6))
TOPN_MID     = int(os.getenv("TOPN_MID", 6))
TOPN_MICRO   = int(os.getenv("TOPN_MICRO", 6))
MIN_ROWS     = int(os.getenv("MIN_ROWS", 180))
W_MIN_VOL    = int(os.getenv("W_MIN_VOL", 20000))
MIN_PRICE    = float(os.getenv("MIN_PRICE", 0.2))
CAPITAL      = float(os.getenv("CAPITAL", 10000))
RISK_PCT     = float(os.getenv("RISK_PCT", 0.01))   # risk 1%/trade default
TAKE_PROFIT  = float(os.getenv("TAKE_PROFIT", 0.06))# +6% target as default TP
STOP_ATR_MULT= float(os.getenv("STOP_ATR_MULT", 1.5))

EODHD_API_KEY= os.getenv("EODHD_API_KEY","")
NEWSAPI_KEY  = os.getenv("NEWSAPI_KEY","")
OPENAI_API_KEY=os.getenv("OPENAI_API_KEY","")

OUT_DIR = "out"
CACHE   = "cache"
os.makedirs(OUT_DIR, exist_ok=True)
os.makedirs(CACHE, exist_ok=True)

# ---- Lazy imports for ML/TA ----
def lazy_imports():
    global xgb, yf
    import xgboost as xgb
    import yfinance as yf
lazy_imports()
from sklearn.metrics import roc_auc_score, accuracy_score

# ---- Paths for tiers ----
U_LARGE = os.path.join(OUT_DIR, "universe_large.csv")
U_MID   = os.path.join(OUT_DIR, "universe_mid.csv")
U_MICRO = os.path.join(OUT_DIR, "universe_micro.csv")

session = requests.Session()
session.headers.update({"User-Agent":"trade-plan-onepass/1.0"})

def daterange_start(years:int)->str:
    return (TODAY - dt.timedelta(days=365*years)).isoformat()

# ---------- Data ----------
def ax_to_eod(t:str)->str:
    t=t.strip().upper()
    if t.endswith(".AX"): t=t[:-3]
    return f"{t}.AU"

def fetch_eodhd_ohlc(ticker_ax: str, years:int)->pd.DataFrame:
    if not EODHD_API_KEY:
        return pd.DataFrame()
    url = f"https://eodhd.com/api/eod/{ax_to_eod(ticker_ax)}"
    p = {"api_token":EODHD_API_KEY, "period":"d", "fmt":"json", "from":daterange_start(years)}
    r = session.get(url, params=p, timeout=25)
    if r.status_code!=200: return pd.DataFrame()
    try:
        df = pd.DataFrame(r.json())
    except Exception:
        return pd.DataFrame()
    if df.empty: return pd.DataFrame()
    df["date"]=pd.to_datetime(df["date"])
    df.rename(columns={"close":"Close","open":"Open","high":"High","low":"Low","volume":"Volume"}, inplace=True)
    df["Ticker"]=ticker_ax
    return df[["Ticker","date","Open","High","Low","Close","Volume"]]

def fetch_yf_ohlc(ticker_ax:str, years:int)->pd.DataFrame:
    import yfinance as yf
    try:
        df = yf.download(ticker_ax, start=daterange_start(years), end=(TODAY+dt.timedelta(days=1)).isoformat(), progress=False)
        if df.empty: return pd.DataFrame()
        df = df.reset_index().rename(columns={"Date":"date","Open":"Open","High":"High","Low":"Low","Close":"Close","Volume":"Volume"})
        df["Ticker"]=ticker_ax
        return df[["Ticker","date","Open","High","Low","Close","Volume"]]
    except Exception:
        return pd.DataFrame()

def get_prices(ticker_ax:str, years:int)->pd.DataFrame:
    cfile = os.path.join(CACHE, f"{ticker_ax}_ohlc.csv")
    if os.path.exists(cfile):
        try:
            df = pd.read_csv(cfile, parse_dates=["date"])
            need_cols = {"Ticker","date","Open","High","Low","Close","Volume"}
            if not df.empty and need_cols.issubset(df.columns):
                return df
        except Exception:
            pass
    df = fetch_eodhd_ohlc(ticker_ax, years)
    if df.empty:
        df = fetch_yf_ohlc(ticker_ax, years)
    if not df.empty:
        df.to_csv(cfile, index=False)
    return df

# ---------- Features ----------
def atr(df:pd.DataFrame, n:int=14)->pd.Series:
    h,l,c = df["High"], df["Low"], df["Close"]
    prev_c = c.shift(1)
    tr = pd.concat([
        (h-l).abs(),
        (h-prev_c).abs(),
        (l-prev_c).abs()
    ], axis=1).max(axis=1)
    return tr.rolling(n).mean()

def add_features(px:pd.DataFrame)->pd.DataFrame:
    p = px.sort_values("date").copy()
    p["ret1"]  = p["Close"].pct_change(1)
    p["ret5"]  = p["Close"].pct_change(5)
    p["ma5"]   = p["Close"].rolling(5).mean()
    p["ma20"]  = p["Close"].rolling(20).mean()
    p["vol20"] = p["Close"].pct_change().rolling(20).std()
    p["atr14"] = atr(p,14)
    p["trend_up"] = (p["ma5"]>p["ma20"]).astype(int)
    p["vma20"] = p["Volume"].rolling(20).mean()
    p["v_ratio"] = p["Volume"]/(p["vma20"]+1e-9)
    p["next_close"] = p["Close"].shift(-1)
    p["y"] = (p["next_close"]>p["Close"]).astype(int)
    p = p.dropna().reset_index(drop=True)
    return p

# ---------- Sentiment ----------
def news_sentiment(ticker_ax:str)->float:
    # Use NewsAPI titles; OpenAI optional to refine to 0..100
    if not NEWSAPI_KEY:
        return 50.0
    q = ticker_ax.replace(".AX","")
    url = "https://newsapi.org/v2/everything"
    params = {"q": q, "apiKey": NEWSAPI_KEY, "language":"en", "pageSize": 8, "sortBy":"publishedAt"}
    try:
        r = session.get(url, params=params, timeout=15)
        if r.status_code!=200: return 50.0
        arts = r.json().get("articles",[])
        if not arts: return 50.0
        titles = [a.get("title","") for a in arts if a.get("title")]
        text = " | ".join(titles)[:4000]
    except Exception:
        return 50.0

    # without OpenAI => simple rule
    if not OPENAI_API_KEY:
        pos = sum(1 for t in titles if any(k in t.lower() for k in ["beats","record","surge","upgrade","strong","rally","profit","guidance raise","wins"]))
        neg = sum(1 for t in titles if any(k in t.lower() for k in ["miss","downgrade","cut","plunge","slump","warn","lawsuit","recall","guidance cut"]))
        raw = 50 + 10*(pos-neg)
        return float(max(0,min(100,raw)))

    # Optional: refine with OpenAI if you have quota
    try:
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)
        prompt = f"Score the overall *trading* sentiment for these recent headlines about {ticker_ax} between 0(bearish) and 100(bullish). Return just a number.\n\n{text}"
        resp = client.chat.completions.create(model="gpt-4o-mini", messages=[{"role":"user","content":prompt}], temperature=0)
        s = resp.choices[0].message.content.strip()
        num = float(''.join(ch for ch in s if (ch.isdigit() or ch=='.')))
        return float(max(0,min(100,num)))
    except Exception:
        return 50.0

# ---------- ML per tier ----------
def train_and_rank(tickers:List[str], topN:int, label:str)->pd.DataFrame:
    rows = []
    for t in tqdm(tickers, desc=f"{label} OHLCV", unit="stk"):
        px = get_prices(t, YEARS)
        if px.empty or len(px)<MIN_ROWS: 
            continue
        # liquidity guard (use last row vma20 and price)
        v20 = px["Volume"].rolling(20).mean()
        if v20.iloc[-1] < W_MIN_VOL or px["Close"].iloc[-1] < MIN_PRICE:
            continue
        fx = add_features(px)
        if fx.empty: 
            continue
        fx["Ticker"]=t
        rows.append(fx)
    if not rows:
        return pd.DataFrame(columns=["Ticker","date","Close","MLProb","Sentiment","Blended","BuyPrice","Stop","Target2","Qty","Capital","AUC","Acc"])

    data = pd.concat(rows, ignore_index=True)
    data = data.sort_values(["Ticker","date"])
    cutoff = data["date"].max() - pd.Timedelta(days=TEST_DAYS)

    feat = ["Close","ma5","ma20","vol20","atr14","trend_up","v_ratio","ret1","ret5"]
    train = data[data["date"]<=cutoff]
    test  = data[data["date"]> cutoff]
    if train["y"].nunique()<2:
        # edge case: fallback to naive scores
        latest = data.groupby("Ticker").tail(1).copy()
        latest["MLProb"] = 0.5
    else:
        model = xgb.XGBClassifier(
            n_estimators=300, max_depth=5, learning_rate=0.05,
            subsample=0.8, colsample_bytree=0.8, n_jobs=4, tree_method="hist",
            eval_metric="auc"
        )
        model.fit(train[feat], train["y"])
        if not test.empty and test["y"].nunique()>1:
            p = model.predict_proba(test[feat])[:,1]
            auc = roc_auc_score(test["y"], p)
            acc = accuracy_score(test["y"], (p>=0.5).astype(int))
        else:
            auc, acc = np.nan, np.nan

        latest = data.groupby("Ticker").tail(1).copy()
        latest["MLProb"] = model.predict_proba(latest[feat])[:,1]
        latest["AUC"] = auc
        latest["Acc"] = acc

    # sentiment per ticker
    sents = {}
    for t in tqdm(latest["Ticker"].tolist(), desc=f"{label} News", unit="stk"):
        sents[t]= news_sentiment(t)

    latest["Sentiment"] = latest["Ticker"].map(sents).astype(float)
    latest["Blended"]   = 0.7*latest["MLProb"] + 0.3*(latest["Sentiment"]/100.0)

    # trading plan fields
    latest["BuyPrice"] = latest["Close"]
    # basic ATR stop/target
    latest["Stop"]     = (latest["Close"] - STOP_ATR_MULT*latest["atr14"]).clip(lower=0)
    latest["Target2"]  = latest["Close"] * (1.0 + TAKE_PROFIT)

    # Kelly-lite position sizing from MLProb
    edge = (latest["MLProb"] - 0.5) * 2.0   # -1..+1
    edge = edge.clip(lower=0)               # only risk when > 0.5
    # risk $ per trade
    risk_dollars = CAPITAL * RISK_PCT
    # qty based on stop distance (protect against zero or tiny stops)
    stop_dist = (latest["BuyPrice"] - latest["Stop"]).replace(0, np.nan)
    latest["Qty"] = (risk_dollars / stop_dist).fillna(0)
    latest["Qty"] = (latest["Qty"] * (0.25 + 0.75*edge)).round()  # scale qty by confidence
    latest["Capital"] = (latest["Qty"] * latest["BuyPrice"]).round(2)

    keep = ["Ticker","date","Close","MLProb","Sentiment","Blended","BuyPrice","Stop","Target2","Qty","Capital","AUC","Acc"]
    latest = latest[keep].sort_values("Blended", ascending=False).head(topN).reset_index(drop=True)
    latest.insert(0,"Rank", latest.index+1)
    latest.insert(1,"Tier", label)
    return latest

def read_tickers(path:str)->List[str]:
    if not os.path.exists(path):
        return []
    df = pd.read_csv(path)
    col = None
    for c in ["Ticker","Code","Symbol","ticker"]:
        if c in df.columns:
            col = c
            break
    if not col:
        return []
    ticks = df[col].astype(str).str.upper().str.strip().tolist()
    ticks = [t if t.endswith(".AX") else f"{t}.AX" for t in ticks]
    return ticks

def main():
    print(f"Config → years={YEARS} | test_days={TEST_DAYS} | topN L/M/m = {TOPN_LARGE}/{TOPN_MID}/{TOPN_MICRO}")
    uni_large = read_tickers(U_LARGE)
    uni_mid   = read_tickers(U_MID)
    uni_micro = read_tickers(U_MICRO)

    if not (uni_large or uni_mid or uni_micro):
        print("No universe files found. Run build_tiers_from_eodhd.py first.")
        sys.exit(1)

    out_all = []
    if uni_large: out_all.append(train_and_rank(uni_large, TOPN_LARGE, "large"))
    if uni_mid:   out_all.append(train_and_rank(uni_mid,   TOPN_MID,   "mid"))
    if uni_micro: out_all.append(train_and_rank(uni_micro, TOPN_MICRO, "micro"))

    if not out_all:
        print("No candidates — loosen filters or check data/API.")
        sys.exit(0)

    plan = pd.concat(out_all, ignore_index=True)
    plan = plan.sort_values(["Tier","Blended"], ascending=[True,False]).reset_index(drop=True)
    fn = os.path.join(OUT_DIR, f"trade_plan_{TODAY.isoformat()}.csv")
    plan.to_csv(fn, index=False)
    print(f"\nSaved: {fn}\n")

    # Pretty print
    def fmt(v, p=3):
        return f"{v:.{p}f}" if isinstance(v, (int,float,np.floating)) else str(v)

    for tier in ["large","mid","micro"]:
        sub = plan[plan["Tier"]==tier].copy()
        if sub.empty: continue
        print(f"=== {tier.capitalize()} Picks ===")
        show = sub[["Rank","Ticker","Close","MLProb","Sentiment","Blended","BuyPrice","Stop","Target2","Qty","Capital"]]
        print(show.to_string(index=False, formatters={
            "Close":lambda x:f"{x:.2f}",
            "MLProb":lambda x:f"{x:.3f}",
            "Sentiment":lambda x:f"{x:.0f}",
            "Blended":lambda x:f"{x:.3f}",
            "BuyPrice":lambda x:f"{x:.2f}",
            "Stop":lambda x:f"{x:.2f}",
            "Target2":lambda x:f"{x:.2f}",
            "Qty":lambda x:f"{int(x)}",
            "Capital":lambda x:f"{x:.0f}",
        }))
        print()

